import{_ as s,c as a,b as p,o as t}from"./app-C01vnHKY.js";const e={};function o(c,n){return t(),a("div",null,n[0]||(n[0]=[p(`<h1 id="实战篇-情感分析-如何使用-lstm-进行情感分析" tabindex="-1"><a class="header-anchor" href="#实战篇-情感分析-如何使用-lstm-进行情感分析"><span>实战篇-情感分析：如何使用 LSTM 进行情感分析</span></a></h1><p>欢迎来跟我一起学习情感分析，今天我们要讲的就是机器学习里的文本情感分析。文本情感分析又叫做观点提取、主题分析、倾向性分析等。光说概念，你可能会觉得有些抽象，我们一起来看一个生活中的应用，你一看就能明白了。</p><p>比方说我们在购物网站上选购一款商品时，首先会翻阅一下商品评价，看看是否有中差评。这些评论信息表达了人们的各种情感色彩和情感倾向性，如喜、怒、哀、乐和批评、赞扬等。像这样根据评价文本，由计算机自动区分评价属于好评、中评或者说差评，背后用到的技术就是情感分析。</p><p>如果你进一步观察，还会发现，在好评差评的上方还有一些标签，比如“声音大小合适”、“连接速度快”、“售后态度很好”等。这些标签其实也是计算机根据文本，自动提取的主题或者观点。</p><p><img src="https://static001.geekbang.org/resource/image/ef/6f/ef69caa72565c50d98b63e20f499ea6f.jpg?wh=2572x2473" alt=""></p><p>情感分析的快速发展得益于社交媒体的兴起，自 2000 年初以来，情感分析已经成长为自然语言处理（NLP）中最活跃的研究领域之一，它也被广泛应用在个性化推荐、商业决策、舆情监控等方面。</p><p>今天这节课，我们将完成一个情感分析项目，一起来对影评文本做分析。</p><h2 id="数据准备" tabindex="-1"><a class="header-anchor" href="#数据准备"><span>数据准备</span></a></h2><p>现在我们手中有一批影评数据（IMDB 数据集），影评被分为两类：正面评价与负面评价。我们需要训练一个情感分析模型，对影评文本进行分类。</p><p>这个问题本质上还是一个文本分类问题，研究对象是电影评论类的文本，我们需要对文本进行二分类。下面我们来看一看训练数据。</p><p>IMDB（Internet Movie Database）是一个来自互联网电影数据库，其中包含了 50000 条严重两极分化的电影评论。数据集被划分为训练集和测试集，其中训练集和测试集中各有 25000 条评论，并且训练集和测试集都包含 50%的正面评论和 50%的消极评论。</p><h3 id="如何用-torchtext-读取数据集" tabindex="-1"><a class="header-anchor" href="#如何用-torchtext-读取数据集"><span>如何用 Torchtext 读取数据集</span></a></h3><p>我们可以利用 Torchtext 工具包来读取数据集。</p><p>Torchtext 是一个包含<strong>常用的文本处理工具</strong>和<strong>常见自然语言数据集</strong>的工具包。我们可以类比之前学习过的 Torchvision 包来理解它，只不过，Torchvision 包是用来处理图像的，而 Torchtext 则是用来处理文本的。</p><p>安装 Torchtext 同样很简单，我们可以使用 pip 进行安装，命令如下：</p><div class="language-plain line-numbers-mode" data-highlighter="prismjs" data-ext="plain"><pre><code><span class="line">pip install torchtext</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Torchtext 中包含了上面我们要使用的 IMDB 数据集，并且还有读取语料库、词转词向量、词转下标、建立相应迭代器等功能，可以满足我们对文本的处理需求。</p><p>更为方便的是，Torchtext 已经把一些常见对文本处理的数据集囊括在了<code>torchtext.datasets</code>中，与 Torchvision 类似，使用时会自动下载、解压并解析数据。</p><p>以 IMDB 为例，我们可以用后面的代码来读取数据集：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 读取IMDB数据集</span></span>
<span class="line"><span class="token keyword">import</span> torchtext</span>
<span class="line">train_iter <span class="token operator">=</span> torchtext<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>IMDB<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">&#39;train&#39;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token builtin">next</span><span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>torchtext.datasets.IMDB 函数有两个参数，其中：</p><ul><li>root：是一个字符串，用于指定你想要读取目标数据集的位置，如果数据集不存在，则会自动下载；</li><li>split：是一个字符串或者元组，表示返回的数据集类型，是训练集、测试集或验证集，默认是  (‘train’, ‘test’)。 torchtext.datasets.IMDB 函数的返回值是一个迭代器，这里我们读取了 IMDB 数据集中的训练集，共 25000 条数据，存入了变量 train_iter 中。</li></ul><p>程序运行的结果如下图所示。我们可以看到，利用 next()函数，读取出迭代器 train_iter 中的一条数据，每一行是情绪分类以及后面的评论文本。“neg”表示负面评价，“pos”表示正面评价。</p><p><img src="https://static001.geekbang.org/resource/image/e4/e6/e4625437cafc8bb29851fb57a9b3e8e6.png?wh=1920x616" alt="图片"></p><h3 id="数据处理-pipelines" tabindex="-1"><a class="header-anchor" href="#数据处理-pipelines"><span>数据处理 pipelines</span></a></h3><p>读取出了数据集中的评论文本和情绪分类，我们还需要将文本和分类标签处理成向量，才能被计算机读取。处理文本的一般过程是先分词，然后根据词汇表将词语转换为 id。</p><p>Torchtext 为我们提供了基本的文本处理工具，包括分词器“tokenizer”和词汇表“vocab”。我们可以用下面两个函数来创建分词器和词汇表。</p><p>get_tokenizer 函数的作用是创建一个分词器。将文本喂给相应的分词器，分词器就可以根据不同分词函数的规则完成分词。例如英文的分词器，就是简单按照空格和标点符号进行分词。</p><p>build_vocab_from_iterator 函数可以帮助我们使用训练数据集的迭代器构建词汇表，构建好词汇表后，输入分词后的结果，即可返回每个词语的 id。</p><p>创建分词器和构建词汇表的代码如下。首先我们要建立一个可以处理英文的分词器 tokenizer，然后再根据 IMDB 数据集的训练集迭代器 train_iter 建立词汇表 vocab。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 创建分词器</span></span>
<span class="line">tokenizer <span class="token operator">=</span> torchtext<span class="token punctuation">.</span>data<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>get_tokenizer<span class="token punctuation">(</span><span class="token string">&#39;basic_english&#39;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">(</span><span class="token string">&#39;here is the an example!&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token triple-quoted-string string">&#39;&#39;&#39;</span>
<span class="line">输出：[&#39;here&#39;, &#39;is&#39;, &#39;the&#39;, &#39;an&#39;, &#39;example&#39;, &#39;!&#39;]</span>
<span class="line">&#39;&#39;&#39;</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 构建词汇表</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">yield_tokens</span><span class="token punctuation">(</span>data_iter<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">for</span> _<span class="token punctuation">,</span> text <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">yield</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">vocab <span class="token operator">=</span> torchtext<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>build_vocab_from_iterator<span class="token punctuation">(</span>yield_tokens<span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span><span class="token punctuation">,</span> specials<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;&lt;pad&gt;&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;&lt;unk&gt;&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">vocab<span class="token punctuation">.</span>set_default_index<span class="token punctuation">(</span>vocab<span class="token punctuation">[</span><span class="token string">&quot;&lt;unk&gt;&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>vocab<span class="token punctuation">(</span>tokenizer<span class="token punctuation">(</span><span class="token string">&#39;here is the an example &lt;pad&gt; &lt;pad&gt;&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token triple-quoted-string string">&#39;&#39;&#39;</span>
<span class="line">输出：[131, 9, 40, 464, 0, 0]</span>
<span class="line">&#39;&#39;&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在构建词汇表的过程中，yield_tokens 函数的作用就是依次将训练数据集中的每一条数据都进行分词处理。另外，在构建词汇表时，用户还可以利用 specials 参数自定义词表。</p><p>上述代码中我们自定义了两个词语：“pad”和“unk”，分别表示占位符和未登录词。顾名思义，未登录词是指没有被收录在分词词表中的词。由于每条影评文本的长度不同，不能直接批量合成矩阵，因此需通过截断或填补占位符来固定长度。</p><p>为了方便后续调用，我们使用分词器和词汇表来建立数据处理的 pipelines。文本 pipeline 用于给定一段文本，返回分词后的 id。标签 pipeline 用于将情绪分类转化为数字，即“neg”转化为 0，“pos”转化为 1。</p><p>具体代码如下所示。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 数据处理pipelines</span></span>
<span class="line">text_pipeline <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> vocab<span class="token punctuation">(</span>tokenizer<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">label_pipeline <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token number">1</span> <span class="token keyword">if</span> x <span class="token operator">==</span> <span class="token string">&#39;pos&#39;</span> <span class="token keyword">else</span> <span class="token number">0</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>text_pipeline<span class="token punctuation">(</span><span class="token string">&#39;here is the an example&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token triple-quoted-string string">&#39;&#39;&#39;</span>
<span class="line">输出：[131, 9, 40, 464, 0, 0 , ... , 0]</span>
<span class="line">&#39;&#39;&#39;</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>label_pipeline<span class="token punctuation">(</span><span class="token string">&#39;neg&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token triple-quoted-string string">&#39;&#39;&#39;</span>
<span class="line">输出：0</span>
<span class="line">&#39;&#39;&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过示例的输出结果，相信你很容易就能理解文本 pipeline 和标签 pipeline 的用法了。</p><h3 id="生成训练数据" tabindex="-1"><a class="header-anchor" href="#生成训练数据"><span>生成训练数据</span></a></h3><p>有了数据处理的 pipelines，接下来就是生成训练数据，也就是生成 DataLoader。</p><p>这里还涉及到一个变长数据处理的问题。我们在将文本 pipeline 所生成的 id 列表转化为模型能够识别的 tensor 时，由于文本的句子是变长的，因此生成的 tensor 长度不一，无法组成矩阵。</p><p>这时，我们需要限定一个句子的最大长度。例如句子的最大长度为 256 个单词，那么超过 256 个单词的句子需要做截断处理；不足 256 个单词的句子，需要统一补位，这里用“pad”来填补。</p><p>上面所说的这些操作，我们都可以放到 collate_batch 函数中来处理。</p><p>collate_batch 函数有什么用呢？它负责在 DataLoad 提取一个 batch 的样本时，完成一系列预处理工作：包括生成文本的 tensor、生成标签的 tensor、生成句子长度的 tensor，以及上面所说的对文本进行截断、补位操作。所以，我们将 collate_batch 函数通过参数 collate_fn 传入 DataLoader，即可实现对变长数据的处理。</p><p>collate_batch 函数的定义，以及生成训练与验证 DataLoader 的代码如下。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 生成训练数据</span></span>
<span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"><span class="token keyword">import</span> torchtext</span>
<span class="line"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</span>
<span class="line"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> random_split</span>
<span class="line"><span class="token keyword">from</span> torchtext<span class="token punctuation">.</span>data<span class="token punctuation">.</span>functional <span class="token keyword">import</span> to_map_style_dataset</span>
<span class="line"></span>
<span class="line">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">collate_batch</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    max_length <span class="token operator">=</span> <span class="token number">256</span></span>
<span class="line">    pad <span class="token operator">=</span> text_pipeline<span class="token punctuation">(</span><span class="token string">&#39;&lt;pad&gt;&#39;</span><span class="token punctuation">)</span></span>
<span class="line">    label_list<span class="token punctuation">,</span> text_list<span class="token punctuation">,</span> length_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">    <span class="token keyword">for</span> <span class="token punctuation">(</span>_label<span class="token punctuation">,</span> _text<span class="token punctuation">)</span> <span class="token keyword">in</span> batch<span class="token punctuation">:</span></span>
<span class="line">         label_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_pipeline<span class="token punctuation">(</span>_label<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">         processed_text <span class="token operator">=</span> text_pipeline<span class="token punctuation">(</span>_text<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>max_length<span class="token punctuation">]</span></span>
<span class="line">         length_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>processed_text<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">         text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>processed_text<span class="token operator">+</span>pad<span class="token operator">*</span>max_length<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>max_length<span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">    label_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>label_list<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span></span>
<span class="line">    text_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>text_list<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span></span>
<span class="line">    length_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>length_list<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> label_list<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> text_list<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> length_list<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">train_iter <span class="token operator">=</span> torchtext<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>IMDB<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">&#39;train&#39;</span><span class="token punctuation">)</span></span>
<span class="line">train_dataset <span class="token operator">=</span> to_map_style_dataset<span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span></span>
<span class="line">num_train <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.95</span><span class="token punctuation">)</span></span>
<span class="line">split_train_<span class="token punctuation">,</span> split_valid_ <span class="token operator">=</span> random_split<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> </span>
<span class="line">                                         <span class="token punctuation">[</span>num_train<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span> <span class="token operator">-</span> num_train<span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>split_train_<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_batch<span class="token punctuation">)</span></span>
<span class="line">valid_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>split_valid_<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_batch<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们一起梳理一下这段代码的流程，一共是五个步骤。</p><p>1.利用 torchtext 读取 IMDB 的训练数据集，得到训练数据迭代器； 2.使用 to_map_style_dataset 函数将迭代器转化为 Dataset 类型； 3.使用 random_split 函数对 Dataset 进行划分，其中 95%作为训练集，5%作为验证集； 4.生成训练集的 DataLoader； 5.生成验证集的 DataLoader。</p><p>到此为止，数据部分已经全部准备完毕了，接下来我们来进行网络模型的构建。</p><h2 id="模型构建" tabindex="-1"><a class="header-anchor" href="#模型构建"><span>模型构建</span></a></h2><p>之前我们已经学过卷积神经网络的相关知识。卷积神经网络使用固定的大小矩阵作为输入（例如一张图片），然后输出一个固定大小的向量（例如不同类别的概率），因此适用于图像分类、目标检测、图像分割等等。</p><p>但是除了图像之外，还有很多信息，其大小或长度并不是固定的，例如音频、视频、文本等。我们想要处理这些序列相关的数据，就要用到时序模型。比如我们今天要处理的文本数据，这就涉及一种常见的时间序列模型：循环神经网络（Recurrent Neural Network，RNN）。</p><p>不过由于 RNN 自身的结构问题，在进行反向传播时，容易出现梯度消失或梯度爆炸。<strong>LSTM 网络</strong>在 RNN 结构的基础上进行了改进，通过精妙的门控制将短时记忆与长时记忆结合起来，<strong>一定程度上解决了梯度消失与梯度爆炸的问题</strong>。</p><p>我们使用 LSTM 网络来进行情绪分类的预测。模型的定义如下。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 定义模型</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">LSTM</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> bidirectional<span class="token punctuation">,</span></span>
<span class="line">                 dropout_rate<span class="token punctuation">,</span> pad_index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> padding_idx<span class="token operator">=</span>pad_index<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> bidirectional<span class="token operator">=</span>bidirectional<span class="token punctuation">,</span></span>
<span class="line">                            dropout<span class="token operator">=</span>dropout_rate<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim <span class="token operator">*</span> <span class="token number">2</span> <span class="token keyword">if</span> bidirectional <span class="token keyword">else</span> hidden_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout_rate<span class="token punctuation">)</span></span>
<span class="line">        </span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ids<span class="token punctuation">,</span> length<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>ids<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        packed_embedded <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>pack_padded_sequence<span class="token punctuation">(</span>embedded<span class="token punctuation">,</span> length<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> </span>
<span class="line">                                                            enforce_sorted<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></span>
<span class="line">        packed_output<span class="token punctuation">,</span> <span class="token punctuation">(</span>hidden<span class="token punctuation">,</span> cell<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">(</span>packed_embedded<span class="token punctuation">)</span></span>
<span class="line">        output<span class="token punctuation">,</span> output_length <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>pad_packed_sequence<span class="token punctuation">(</span>packed_output<span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">if</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">.</span>bidirectional<span class="token punctuation">:</span></span>
<span class="line">            hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>hidden<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">else</span><span class="token punctuation">:</span></span>
<span class="line">            hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>hidden<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">        prediction <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>hidden<span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">return</span> prediction</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>网络模型的具体结构，首先是一个 Embedding 层，用来接收文本 id 的 tensor，然后是 LSTM 层，最后是一个全连接分类层。其中，bidirectional 为 True，表示网络为双向 LSTM，bidirectional 为 False，表示网络为单向 LSTM。</p><p>网络模型的结构图如下所示。</p><p><img src="https://static001.geekbang.org/resource/image/f4/a8/f4013742ab70b0dc405948f07198cfa8.jpg?wh=619x404" alt="图片"></p><h2 id="模型训练与评估" tabindex="-1"><a class="header-anchor" href="#模型训练与评估"><span>模型训练与评估</span></a></h2><p>定义好网络模型的结构，我们就可以进行模型训练了。首先是实例化网络模型，参数以及具体的代码如下。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 实例化模型</span></span>
<span class="line">vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span></span>
<span class="line">embedding_dim <span class="token operator">=</span> <span class="token number">300</span></span>
<span class="line">hidden_dim <span class="token operator">=</span> <span class="token number">300</span></span>
<span class="line">output_dim <span class="token operator">=</span> <span class="token number">2</span></span>
<span class="line">n_layers <span class="token operator">=</span> <span class="token number">2</span></span>
<span class="line">bidirectional <span class="token operator">=</span> <span class="token boolean">True</span></span>
<span class="line">dropout_rate <span class="token operator">=</span> <span class="token number">0.5</span></span>
<span class="line"></span>
<span class="line">model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> bidirectional<span class="token punctuation">,</span> dropout_rate<span class="token punctuation">)</span></span>
<span class="line">model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>由于数据的情感极性共分为两类，因此这里我们要把 output_dim 的值设置为 2。 接下来是定义损失函数与优化方法，代码如下。在之前的课程里也多次讲过了，所以这里不再重复。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 损失函数与优化方法</span></span>
<span class="line">lr <span class="token operator">=</span> <span class="token number">5e-4</span></span>
<span class="line">criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">criterion <span class="token operator">=</span> criterion<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>计算 loss 的代码如下。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token keyword">import</span> tqdm</span>
<span class="line"><span class="token keyword">import</span> sys</span>
<span class="line"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</span>
<span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    epoch_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">    epoch_accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">    <span class="token keyword">for</span> batch <span class="token keyword">in</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">&#39;training...&#39;</span><span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token punctuation">(</span>label<span class="token punctuation">,</span> ids<span class="token punctuation">,</span> length<span class="token punctuation">)</span> <span class="token operator">=</span> batch</span>
<span class="line">        label <span class="token operator">=</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">        ids <span class="token operator">=</span> ids<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">        length <span class="token operator">=</span> length<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">        prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>ids<span class="token punctuation">,</span> length<span class="token punctuation">)</span></span>
<span class="line">        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token comment"># loss计算</span></span>
<span class="line">        accuracy <span class="token operator">=</span> get_accuracy<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 梯度更新</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        epoch_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        epoch_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>accuracy<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> epoch_losses<span class="token punctuation">,</span> epoch_accs</span>
<span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    epoch_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">    epoch_accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">for</span> batch <span class="token keyword">in</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">&#39;evaluating...&#39;</span><span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">            <span class="token punctuation">(</span>label<span class="token punctuation">,</span> ids<span class="token punctuation">,</span> length<span class="token punctuation">)</span> <span class="token operator">=</span> batch</span>
<span class="line">            label <span class="token operator">=</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">            ids <span class="token operator">=</span> ids<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">            length <span class="token operator">=</span> length<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">            prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>ids<span class="token punctuation">,</span> length<span class="token punctuation">)</span></span>
<span class="line">            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token comment"># loss计算</span></span>
<span class="line">            accuracy <span class="token operator">=</span> get_accuracy<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span></span>
<span class="line">            epoch_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">            epoch_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>accuracy<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> epoch_losses<span class="token punctuation">,</span> epoch_accs</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以看到，这里训练过程与验证过程的 loss 计算，分别定义在了 train 函数和 evaluate 函数中。主要区别是训练过程有梯度的更新，而验证过程中不涉及梯度的更新，只计算 loss 即可。 模型的评估我们使用 ACC，也就是准确率作为评估指标，计算 ACC 的代码如下。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">get_accuracy</span><span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    batch_size<span class="token punctuation">,</span> _ <span class="token operator">=</span> prediction<span class="token punctuation">.</span>shape</span>
<span class="line">    predicted_classes <span class="token operator">=</span> prediction<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">    correct_predictions <span class="token operator">=</span> predicted_classes<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    accuracy <span class="token operator">=</span> correct_predictions <span class="token operator">/</span> batch_size</span>
<span class="line">    <span class="token keyword">return</span> accuracy</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>最后，训练过程的具体代码如下。包括计算 loss 和 ACC、保存 losses 列表和保存最优模型。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">n_epochs <span class="token operator">=</span> <span class="token number">10</span></span>
<span class="line">best_valid_loss <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">&#39;inf&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">train_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">train_accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">valid_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">valid_accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    train_loss<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span></span>
<span class="line">    valid_loss<span class="token punctuation">,</span> valid_acc <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>valid_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> device<span class="token punctuation">)</span></span>
<span class="line">    train_losses<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span></span>
<span class="line">    train_accs<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span></span>
<span class="line">    valid_losses<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>valid_loss<span class="token punctuation">)</span></span>
<span class="line">    valid_accs<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>valid_acc<span class="token punctuation">)</span> </span>
<span class="line">    epoch_train_loss <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span></span>
<span class="line">    epoch_train_acc <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span></span>
<span class="line">    epoch_valid_loss <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>valid_loss<span class="token punctuation">)</span></span>
<span class="line">    epoch_valid_acc <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>valid_acc<span class="token punctuation">)</span>    </span>
<span class="line">    <span class="token keyword">if</span> epoch_valid_loss <span class="token operator">&lt;</span> best_valid_loss<span class="token punctuation">:</span></span>
<span class="line">        best_valid_loss <span class="token operator">=</span> epoch_valid_loss</span>
<span class="line">        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;lstm.pt&#39;</span><span class="token punctuation">)</span>   </span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;epoch: </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;train_loss: </span><span class="token interpolation"><span class="token punctuation">{</span>epoch_train_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">, train_acc: </span><span class="token interpolation"><span class="token punctuation">{</span>epoch_train_acc<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;valid_loss: </span><span class="token interpolation"><span class="token punctuation">{</span>epoch_valid_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">, valid_acc: </span><span class="token interpolation"><span class="token punctuation">{</span>epoch_valid_acc<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们还可以利用保存下来 train_losses 列表，绘制训练过程中的 loss 曲线，或使用[第 15 课]讲过的可视化工具来监控训练过程。 至此，一个完整的情感分析项目已经完成了。从数据读取到模型构建与训练的方方面面，我都手把手教给了你，希望你能以此为模板，独立解决自己的问题。</p><h2 id="小结" tabindex="-1"><a class="header-anchor" href="#小结"><span>小结</span></a></h2><p>恭喜你，完成了今天的学习任务。今天我们一起完成了一个情感分析项目的实践，相当于是对自然语言处理任务的一个初探。我带你回顾一下今天学习的要点。</p><p>在数据准备阶段，我们可以使用 PyTorch 提供的文本处理工具包 Torchtext。想要掌握 Torchtext 也不难，我们可以类比之前详细介绍过的 Torchvision，不懂的地方再对应去<a href="https://pytorch.org/text/stable/index.html" target="_blank" rel="noopener noreferrer">查阅文档</a>，相信你一定可以做到举一反三。</p><p><strong>模型构建时，要根据具体的问题选择适合的神经网络。卷积神经网络常被用于处理图像作为输入的预测问题；循环神经网络常被用于处理变长的、序列相关的数据。而 LSTM 相较于 RNN，能更好地解决梯度消失与梯度爆炸的问题</strong>。</p><p>在后续的课程中，我们还会讲解两大自然语言处理任务：文本分类和摘要生成，它们分别包括了判别模型和生成模型，相信那时你一定会在文本处理方面有更深层次的理解。</p><h2 id="每课一练" tabindex="-1"><a class="header-anchor" href="#每课一练"><span>每课一练</span></a></h2><p>利用今天训练的模型，编写一个函数 predict_sentiment，实现输入一句话，输出这句话的情绪类别与概率。</p><p>例如：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">text <span class="token operator">=</span> <span class="token string">&quot;This film is terrible!&quot;</span></span>
<span class="line">predict_sentiment<span class="token punctuation">(</span>text<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> vocab<span class="token punctuation">,</span> device<span class="token punctuation">)</span></span>
<span class="line"><span class="token triple-quoted-string string">&#39;&#39;&#39;</span>
<span class="line">输出：(&#39;neg&#39;, 0.8874172568321228)</span>
<span class="line">&#39;&#39;&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>欢迎你在留言区跟我交流互动，也推荐你把今天学到的内容分享给更多朋友，跟他一起学习进步。</p>`,79)]))}const i=s(e,[["render",o]]),u=JSON.parse('{"path":"/3.tech/83.PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/23_%E5%AE%9E%E6%88%98%E7%AF%87-%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8LSTM%E8%BF%9B%E8%A1%8C%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.html","title":"实战篇-情感分析：如何使用 LSTM 进行情感分析","lang":"zh-cn","frontmatter":{},"headers":[{"level":2,"title":"数据准备","slug":"数据准备","link":"#数据准备","children":[{"level":3,"title":"如何用 Torchtext 读取数据集","slug":"如何用-torchtext-读取数据集","link":"#如何用-torchtext-读取数据集","children":[]},{"level":3,"title":"数据处理 pipelines","slug":"数据处理-pipelines","link":"#数据处理-pipelines","children":[]},{"level":3,"title":"生成训练数据","slug":"生成训练数据","link":"#生成训练数据","children":[]}]},{"level":2,"title":"模型构建","slug":"模型构建","link":"#模型构建","children":[]},{"level":2,"title":"模型训练与评估","slug":"模型训练与评估","link":"#模型训练与评估","children":[]},{"level":2,"title":"小结","slug":"小结","link":"#小结","children":[]},{"level":2,"title":"每课一练","slug":"每课一练","link":"#每课一练","children":[]}],"git":{"updatedTime":1746672966000,"contributors":[{"name":"guoxin-qiu","username":"guoxin-qiu","email":"guoxin.qiu@outlook.com","commits":3,"url":"https://github.com/guoxin-qiu"}],"changelog":[{"hash":"873191059aa4709eddd6184a409223b5054edb2a","time":1746672966000,"email":"guoxin.qiu@outlook.com","author":"guoxin-qiu","message":"update: pytorch fixed"},{"hash":"f2ddff143d5e7042818e92930c2e210f4b633ca8","time":1746603363000,"email":"guoxin.qiu@outlook.com","author":"guoxin-qiu","message":"update: 250507 bugfix"},{"hash":"b44b80ec6b8c2ebffa55c7b2b54259609c76baed","time":1745668690000,"email":"guoxin.qiu@outlook.com","author":"guoxin-qiu","message":"add pytorch course"}]},"filePathRelative":"3.tech/83.PyTorch深度学习实战/23_实战篇-情感分析：如何使用LSTM进行情感分析.md"}');export{i as comp,u as data};
