import{_ as s,c as a,b as p,o as t}from"./app-C01vnHKY.js";const e={};function o(c,n){return t(),a("div",null,n[0]||(n[0]=[p(`<h1 id="模型训练篇-卷积-上-如何用卷积为计算机开天眼" tabindex="-1"><a class="header-anchor" href="#模型训练篇-卷积-上-如何用卷积为计算机开天眼"><span>模型训练篇-卷积（上）：如何用卷积为计算机开天眼</span></a></h1><p>现在刷脸支付的场景越来越多，相信人脸识别你一定不陌生，你有没有想过，在计算机识别人脸之前，我们人类是如何判断一个人是谁的呢？</p><p>我们眼睛看到人脸的时候，会先将人脸的一些粗粒度特征提取出来，例如人脸的轮廓、头发的颜色、头发长短等。然后这些信息会一层一层地传入到某一些神经元当中，每经过一层神经元就相当于特征提取。我们大脑最终会将最后的特征进行汇总，类似汇总成一张具体的人脸，用这张人脸去大脑的某一个地方与存好的人名进行匹配。</p><p>那落实到我们计算机呢？其实这个过程是一样的，在计算机中进行特征提取的功能，就离不开我们今天要讲的卷积。</p><p>可以说，没有卷积的话，深度学习在图像领域不可能取得今天的成就。 那么，就让我们来看看什么是卷积，还有它在 PyTorch 中的实现吧。</p><h2 id="卷积" tabindex="-1"><a class="header-anchor" href="#卷积"><span>卷积</span></a></h2><p>在使用卷积之前，人们尝试了很多人工神经网络来处理图像问题，但是人工神经网络的参数量非常大，从而导致非常难训练，所以计算机视觉的研究一直停滞不前，难以突破。</p><p>直到卷积神经网络的出现，它的两个优秀特点：稀疏连接与平移不变性，这让计算机视觉的研究取得了长足的进步。什么是稀疏连接与平移不变性呢？简单来说，就是稀疏连接可以让学习的参数变得很少，而平移不变性则不关心物体出现在图像中什么位置。</p><p>稀疏连接与平移不变性是卷积的两个重要特点，如果你想从事计算机视觉相关的工作，这两个特点必须该清楚，但不是本专栏的重点，这里就不展开了，有兴趣你可以自己去了解。</p><p>下面我们直接来看看卷积是如何计算的。</p><h3 id="最简单的情况" tabindex="-1"><a class="header-anchor" href="#最简单的情况"><span>最简单的情况</span></a></h3><p>我们先看最简单的情况，输入是一个 4x4 的特征图，卷积核的大小为 2x2。</p><p>卷积核是什么呢？其实就是我们卷积层要学习到的参数，就像下图中红色的示例，下图中的卷积核是最简单的情况，只有一个通道。</p><p><img src="https://static001.geekbang.org/resource/image/ac/5d/ac84c162ee165d535fcbf465572faf5d.jpg?wh=1075x728" alt="图片"></p><p>输入特征与卷积核计算时，计算方式是卷积核与输入特征按位做乘积运算然后再求和，其结果为输出特征图的一个元素，下图为计算输出特征图第一个元素的计算方式：</p><p><img src="https://static001.geekbang.org/resource/image/78/20/787c8b346de00dayyd7e2d3504c33320.jpg?wh=1561x891" alt="图片"></p><p>完成了第一个元素的计算，我们接着往下看，按以从左向右，从上至下的顺序进行滑动卷积核，分别与输入的特征图进行计算，请看下图，下图为上图计算完毕之后，向右侧滑动一个单元的计算方式：</p><p><img src="https://static001.geekbang.org/resource/image/5y/b5/5yy249d2f1221e21a1bdc7d8756f4fb5.jpg?wh=1544x862" alt="图片"></p><p>第一行第三个单元的计算以此类推。说完了同一行的移动，我们再看看，第一行计算完毕，向下滑动的计算方式是什么样的。</p><p><img src="https://static001.geekbang.org/resource/image/cf/bb/cf4aa3yy8ac31b06f153f9090d3bcebb.jpg?wh=1552x929" alt="图片"></p><p>第一行计算完毕之后，卷积核会回到行首，然后向下滑动一个单元，再重复以上从左至右的滑动计算。</p><p>这里我再给你补充一个知识点，什么是步长？</p><p>卷积上下左右滑动的长度，我们称为步长，用 stride 表示。上述例子中的步长就是 1，根据问题的不同，会取不同的步长，但通常来说步长为 1 或 2。不管是刚才说的最简单的卷积计算，还是我们后面要讲的标准卷积，都要用到这个参数。</p><h3 id="标准的卷积" tabindex="-1"><a class="header-anchor" href="#标准的卷积"><span>标准的卷积</span></a></h3><p>好啦，前面只是最简单的情况，现在我们将最简单的卷积计算方式延伸到标准的卷积计算方式。</p><p>我们先将上面的例子描述为更加通用的形式，输入的特征有 m 个通道，宽为 w，高为 h；输出有 n 个特征图，宽为$w^{\\prime}$，高为$h^{\\prime}$；卷积核的大小为 kxk。</p><p>在刚才的例子中 m、n、k、w、h、$w^{\\prime}$、$h^{\\prime}$的值分别为 1、1、2、4、4、3、3。而现在，我们需要把一个输入为(m，h，w)的输入特征图经过卷积计算，生成一个输出为(n, $h^{\\prime}$, $w^{\\prime}$)的特征图。</p><p>那我们来看看可以获得这个操作的卷积是什么样子的。输出特征图的通道数由<strong>卷积核的个数决定</strong>的，所以说卷积核的个数为 n。根据卷积计算的定义，<strong>输入特征图有 m 个通道，所以每个卷积核里要也要有 m 个通道</strong>。所以，我们的需要 n 个卷积核，每个卷积核的大小为(m, k, k)。</p><p>为了帮你更好地理解刚才所讲的内容，我画了示意图，你可以对照一下：</p><p><img src="https://static001.geekbang.org/resource/image/62/12/62fd6c269cee17e778f8d5acf085be12.jpeg?wh=1920x1080" alt=""></p><p>结合上面的图解可以看到，卷积核 1 与全部输入特征进行卷积计算，就获得了输出特征图中第 1 个通道的数据，卷积核 2 与全部输入特征图进行计算获得输出特征图中第 2 个通道的数据。以此类推，最终就能计算 n 个输出特征图。</p><p>在开篇的例子中，输入只有 1 个通道，现在有多个通道了，那我们该如何计算呢？其实计算方式类似，输入特征的每一个通道与卷积核中对应通道的数据按我们之前讲过的方式进行卷积计算，也就是输入特征图中第 i 个特征图与卷积核中的第 i 个通道的数据进行卷积。这样计算后会生成<strong>m</strong>个特征图，然后将这 m 个特征图按对应位置求和即可，求和后 m 个特征图合并为输出特征中一个通道的特征图。</p><p>我们可以用后面的公式表示当输入有多个通道时，每个卷积核是如何与输入进行计算的。</p><p>$Output_i$表示计算第 i 个输出特征图，i 的取值为 1 到 n；</p><p>$kernel_k$表示 1 个卷积核里的第 k 个通道的数据；</p><p>$input_k$表示输入特征图中的第 k 个通道的数据；</p><p>$bias_k$为偏移项，我们在训练时一般都会默认加上；</p><p>$\\star$为卷积计算；</p><p>$$Output_i = \\sum_{k=0}^{m}kernel_k \\star input_k + bias_i, \\space \\space \\space \\space i=1,2,...,n$$</p><p>我来解释一下为什么要加 bias。就跟回归方程一样，如果不加 bias 的话，回归方程为 y=wx 不管 w 如何变化，回归方程都必须经过原点。如果加上 bias 的话，回归方程变为 y=wx+b，这样就不是必须经过原点，可以变化的更加多样。</p><p>好啦，卷积计算方式的讲解到这里就告一段落了。下面我们看看在卷积层中有关卷积计算的另外一个重要参数。</p><h3 id="padding" tabindex="-1"><a class="header-anchor" href="#padding"><span>Padding</span></a></h3><p>让我们回到开头的例子，可以发现，输入的尺寸是 4x4，输出的尺寸是 3x3。你有没有发现，输出的特征图变小了？没错，在有多层卷积层的神经网络中，特征图会越来越小。</p><p>但是，有的时候我们为了让特征图变得不是那么小，可以对特征图进行补零操作。这样做主要有两个目的：</p><p>1.有的时候需要输入与输出的特征图保持一样的大小； 2.让输入的特征保留更多的信息。</p><p>这里我举个例子，带你看看，一般什么情况下会希望特征图变得不那么小。</p><p>通过刚才的讲解我们知道，如果不补零且步长（stride）为 1 的情况下，当有多层卷积层时，特征图会一点点变小。如果我们希望有更多层卷积层来提取更加丰富的信息时，就可以让特征图变小的速度稍微慢一些，这个时候就可以考虑补零。</p><p>这个补零的操作就叫做 padding，padding 等于 1 就是补一圈的零，等于 2 就是补两圈的零，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/99/08/99dc22a96df665e93e881yy3cf358d08.jpg?wh=1520x792" alt="图片"></p><p>在 Pytorch 中，padding 这个参数可以是字符串、int 和 tuple。</p><p>我们分别来看看不同参数类型怎么使用：当为字符串时只能取$^{\\prime}valid^{\\prime}$与$^{\\prime}same^{\\prime}$。当给定整型时，则是说要在特征图外边补多少圈 0。如果是 tuple 的时候，则是表示在特征图的行与列分别指定补多少零。</p><p>我们重点看一下字符串的形式，相比于直接给定补多少零来说，我认为字符串更加常用。其中，$^{\\prime}valid^{\\prime}$就是没有 padding 操作，就像开头的例子那样。$^{\\prime}same^{\\prime}$则是让输出的特征图与输入的特征图获得相同的大小。</p><p>那当 padding 为 same 时，到底是怎么计算的呢？我们继续用开篇的例子说明，现在 padding 为$^{\\prime}same^{\\prime}$了。</p><p><img src="https://static001.geekbang.org/resource/image/yy/9c/yy51a5c4a35ffa8a06e7d7415aba339c.jpg?wh=1417x736" alt="图片"></p><p>当滑动到特征图最右侧时，发现输出的特征图的宽与输入的特征图的宽不一致，它会自动补零，直到输出特征图的宽与输入特征图的宽一致为止。如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/52/c7/52f8d0ba39b49e9a2736c1a0afb38cc7.jpg?wh=1463x720" alt="图片"></p><p>高的计算和宽的计算同理，当计算到特征图的底部时，发现输出特征图的高与输入特征图的高不一致时，它同样会自动补零，直到输入和输出一致为止，如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/c4/81/c48614da6c7bbcd5abdaf942ea45b481.jpg?wh=1476x735" alt="图片"></p><p>完成上述操作，我们就可以获得与输入特征图有相同高、宽的输出特征图了。理论讲完了，我们还是要学以致用，在实践中深入体会。在下面的练习中，我们会实际考察一下当 padding 为 same 时，是否像我们说的这样计算。</p><h2 id="pytorch-中的卷积" tabindex="-1"><a class="header-anchor" href="#pytorch-中的卷积"><span>PyTorch 中的卷积</span></a></h2><p>卷积操作定义在 torch.nn 模块中，torch.nn 模块为我们提供了很多构建网络的基础层与方法。</p><p>在 torch.nn 模块中，关于今天介绍的卷积操作有 nn.Conv1d、nn.Conv2d 与 nn.Conv3d 三个类。</p><p>请注意，我们上述的例子都是按照 nn.Conv2d 来介绍的，nn.Conv2d 也是用的最多的，而 nn.Conv1d 与 nn.Conv3d 只是输入特征图的维度有所不一样而已，很少会被用到。</p><p>让我们先看看创建一个 nn.Conv2d 需要哪些必须的参数：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># Conv2d类</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">torch</span><span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> </span>
<span class="line">                      out_channels<span class="token punctuation">,</span> </span>
<span class="line">                      kernel_size<span class="token punctuation">,</span> </span>
<span class="line">                      stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> </span>
<span class="line">                      padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> </span>
<span class="line">                      dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> </span>
<span class="line">                      groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> </span>
<span class="line">                      bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> </span>
<span class="line">                      padding_mode<span class="token operator">=</span><span class="token string">&#39;zeros&#39;</span><span class="token punctuation">,</span> </span>
<span class="line">                      device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> </span>
<span class="line">                      dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们挨个说说这些参数。首先是跟通道相关的两个参数：in_channels 是指输入特征图的通道数，数据类型为 int，在标准卷积的讲解中 in_channels 为 m；out_channels 是输出特征图的通道数，数据类型为 int，在标准卷积的讲解中 out_channels 为 n。</p><p>kernel_size 是卷积核的大小，数据类型为 int 或 tuple，需要注意的是只给定卷积核的高与宽即可，在标准卷积的讲解中 kernel_size 为 k。</p><p>stride 为滑动的步长，数据类型为 int 或 tuple，默认是 1，在前面的例子中步长都为 1。</p><p>padding 为补零的方式，注意<strong>当 padding 为&#39;valid&#39;或&#39;same&#39;时，stride 必须为 1</strong>。</p><p>对于 kernel_size、stride、padding 都可以是 tuple 类型，当为 tuple 类型时，第一个维度用于 height 的信息，第二个维度时用于 width 的信息。</p><p>bias 是否使用偏移项。</p><p>还有两个参数：dilation 与 groups，具体内容下节课我们继续展开讲解，你先有个印象就行。</p><h3 id="验证-same-方式" tabindex="-1"><a class="header-anchor" href="#验证-same-方式"><span>验证 same 方式</span></a></h3><p>接下来，我们做一个练习，验证 padding 为 same 时，计算方式是否像我们所说的那样。过程并不复杂，一共三步，分别是创建输入特征图、设置卷积以及输出结果。</p><p>先来看第一步，我们创建好例子中的（4，4，1）大小的输入特征图，代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</span>
<span class="line"></span>
<span class="line">input_feat <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>input_feat<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>input_feat<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 输出：</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">7.</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">7.</span><span class="token punctuation">,</span> <span class="token number">7.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>第二步，创建一个 2x2 的卷积，根据刚才的介绍，输入的通道数为 1，输出的通道数为 1，padding 为&#39;same&#39;，所以卷积定义为：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">conv2d <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&#39;same&#39;</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 默认情况随机初始化参数</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>conv2d<span class="token punctuation">.</span>weight<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>conv2d<span class="token punctuation">.</span>bias<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 输出：</span></span>
<span class="line">Parameter containing<span class="token punctuation">:</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.3235</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1593</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token punctuation">[</span> <span class="token number">0.2548</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1363</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">Parameter containing<span class="token punctuation">:</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4890</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>需要注意的是，默认情况下是随机初始化的。一般情况下，我们不会人工强行干预卷积核的初始化，但是为了验证今天的例子，我们对卷积核的参数进行干预。请注意下面代码中卷积核的注释，代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">conv2d <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&#39;same&#39;</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 卷积核要有四个维度(输入通道数，输出通道数，高，宽)</span></span>
<span class="line">kernels <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span></span>
<span class="line">conv2d<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>kernels<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>conv2d<span class="token punctuation">.</span>weight<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>conv2d<span class="token punctuation">.</span>bias<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 输出：</span></span>
<span class="line">Parameter containing<span class="token punctuation">:</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token boolean">None</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>完成之后就进入了第三步，现在我们已经准备好例子中的输入数据与卷积数据了，下面只需要计算一下，然后输出就可以了，代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">output <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>input_feat<span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span></span>
<span class="line">RuntimeError                              Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">/</span>var<span class="token operator">/</span>folders<span class="token operator">/</span>pz<span class="token operator">/</span>z8t8232j1v17y01bkhyrl01w0000gn<span class="token operator">/</span>T<span class="token operator">/</span>ipykernel_29592<span class="token operator">/</span><span class="token number">2273564149</span><span class="token punctuation">.</span>py <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span></span>
<span class="line"><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token number">1</span> output <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>input_feat<span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">~</span><span class="token operator">/</span>Library<span class="token operator">/</span>Python<span class="token operator">/</span><span class="token number">3.8</span><span class="token operator">/</span>lib<span class="token operator">/</span>python<span class="token operator">/</span>site<span class="token operator">-</span>packages<span class="token operator">/</span>torch<span class="token operator">/</span>nn<span class="token operator">/</span>modules<span class="token operator">/</span>module<span class="token punctuation">.</span>py <span class="token keyword">in</span> _call_impl<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span></span>
<span class="line">   <span class="token number">1049</span>         <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>_backward_hooks <span class="token keyword">or</span> self<span class="token punctuation">.</span>_forward_hooks <span class="token keyword">or</span> self<span class="token punctuation">.</span>_forward_pre_hooks <span class="token keyword">or</span> _global_backward_hooks</span>
<span class="line">   <span class="token number">1050</span>                 <span class="token keyword">or</span> _global_forward_hooks <span class="token keyword">or</span> _global_forward_pre_hooks<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line"><span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token number">1051</span>             <span class="token keyword">return</span> forward_call<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span></span>
<span class="line">   <span class="token number">1052</span>         <span class="token comment"># Do not call functions when jit is used</span></span>
<span class="line">   <span class="token number">1053</span>         full_backward_hooks<span class="token punctuation">,</span> non_full_backward_hooks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line"><span class="token operator">~</span><span class="token operator">/</span>Library<span class="token operator">/</span>Python<span class="token operator">/</span><span class="token number">3.8</span><span class="token operator">/</span>lib<span class="token operator">/</span>python<span class="token operator">/</span>site<span class="token operator">-</span>packages<span class="token operator">/</span>torch<span class="token operator">/</span>nn<span class="token operator">/</span>modules<span class="token operator">/</span>conv<span class="token punctuation">.</span>py <span class="token keyword">in</span> forward<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token number">441</span></span>
<span class="line">    <span class="token number">442</span>     <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span></span>
<span class="line"><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token number">443</span>         <span class="token keyword">return</span> self<span class="token punctuation">.</span>_conv_forward<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span></span>
<span class="line">    <span class="token number">444</span></span>
<span class="line">    <span class="token number">445</span> <span class="token keyword">class</span> <span class="token class-name">Conv3d</span><span class="token punctuation">(</span>_ConvNd<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line"><span class="token operator">~</span><span class="token operator">/</span>Library<span class="token operator">/</span>Python<span class="token operator">/</span><span class="token number">3.8</span><span class="token operator">/</span>lib<span class="token operator">/</span>python<span class="token operator">/</span>site<span class="token operator">-</span>packages<span class="token operator">/</span>torch<span class="token operator">/</span>nn<span class="token operator">/</span>modules<span class="token operator">/</span>conv<span class="token punctuation">.</span>py <span class="token keyword">in</span> _conv_forward<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> weight<span class="token punctuation">,</span> bias<span class="token punctuation">)</span></span>
<span class="line">    <span class="token number">437</span>                             weight<span class="token punctuation">,</span> bias<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span></span>
<span class="line">    <span class="token number">438</span>                             _pair<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>dilation<span class="token punctuation">,</span> self<span class="token punctuation">.</span>groups<span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token number">439</span>         <span class="token keyword">return</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> weight<span class="token punctuation">,</span> bias<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span></span>
<span class="line">    <span class="token number">440</span>                         self<span class="token punctuation">.</span>padding<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dilation<span class="token punctuation">,</span> self<span class="token punctuation">.</span>groups<span class="token punctuation">)</span></span>
<span class="line">    <span class="token number">441</span></span>
<span class="line">RuntimeError<span class="token punctuation">:</span> Expected <span class="token number">4</span><span class="token operator">-</span>dimensional <span class="token builtin">input</span> <span class="token keyword">for</span> <span class="token number">4</span><span class="token operator">-</span>dimensional weight<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> but got <span class="token number">2</span><span class="token operator">-</span>dimensional <span class="token builtin">input</span> of size <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span> instead</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>结合上面代码，你会发现这里报错了，提示信息是输入的特征图需要是一个 4 维的，而我们的输入特征图是一个 4x4 的 2 维特征图。这是为什么呢？ 请你记住，<strong>Pytorch 输入 tensor 的维度信息是(batch_size, 通道数，高，宽)</strong>，但是在我们的例子中只给定了高与宽，没有给定 batch_size（在训练时，不会将所有数据一次性加载进来训练，而是以多个批次进行读取的，每次读取的量成为 batch_size）与通道数。所以，我们要回到第一步将输入的 tensor 改为(1,1,4,4)的形式。</p><p>你还记得我在之前的讲解中提到过怎么对数组添加维度吗？</p><p>在 Pytorch 中 unsqueeze()对 tensor 的维度进行修改。代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">input_feat <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>input_feat<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>input_feat<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 输出：</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">7.</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token punctuation">[</span><span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token punctuation">[</span><span class="token number">7.</span><span class="token punctuation">,</span> <span class="token number">7.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这里，unsqueeze()中的参数是指在哪个位置添加维度。 好，做完了修改，我们再次执行代码。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">output <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>input_feat<span class="token punctuation">)</span></span>
<span class="line">输出：</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">16.</span><span class="token punctuation">,</span> <span class="token number">11.</span><span class="token punctuation">,</span> <span class="token number">16.</span><span class="token punctuation">,</span> <span class="token number">15.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token punctuation">[</span><span class="token number">25.</span><span class="token punctuation">,</span> <span class="token number">20.</span><span class="token punctuation">,</span> <span class="token number">10.</span><span class="token punctuation">,</span> <span class="token number">13.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token punctuation">[</span> <span class="token number">9.</span><span class="token punctuation">,</span>  <span class="token number">9.</span><span class="token punctuation">,</span> <span class="token number">10.</span><span class="token punctuation">,</span> <span class="token number">12.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">          <span class="token punctuation">[</span> <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>你可以看看，跟我们在例子中推导的结果一不一样？</p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p>恭喜你完成了今天的学习。今天所讲的卷积非常重要，它是各种计算机视觉应用的基础，例如图像分类、目标检测、图像分割等。</p><p>卷积的计算方式是你需要关注的重点。具体过程如下图所示，输出特征图的通道数由<strong>卷积核的个数决定</strong>的，下图中因为有 n 个卷积核，所以输出特征图的通道数为 n。<strong>输入特征图有 m 个通道，所以每个卷积核里要也要有 m 个通道</strong>。</p><p><img src="https://static001.geekbang.org/resource/image/62/12/62fd6c269cee17e778f8d5acf085be12.jpeg?wh=1920x1080" alt=""></p><p>其实卷积背后的理论比较复杂，但在 PyTorch 中实现却很简单。在卷积计算中涉及的几大要素：输入通道数、输出通道数、步长、padding、卷积核的大小，分别对应的就是 PyTorch 中 nn.Conv2d 的关键参数。所以，就像前面讲的那样，我们要熟练用好 nn.Conv2d()。</p><p>之后，我还带你做了一个验证 same 方式的练习，动手跑跑代码会帮你形成直观印象，快速掌握这部分内容。</p><p>当然，对于卷积来说不光光有今天介绍的这种比较标准的卷积，还有各种变形。例如，今天没有讲到的 dilation 参数与 groups 参数，基于这两个参数实现的卷积操作，我会在下一节课中为展开，敬请期待。</p><h2 id="每课一练" tabindex="-1"><a class="header-anchor" href="#每课一练"><span>每课一练</span></a></h2><p>请你想一想，padding 为&#39;same&#39;时，stride 可以为 1 以外的数值吗？</p><p>欢迎你在留言区记录你的疑问或收获，也推荐你把这节课分享给更多朋友、同事。</p><p>我是方远，我们下节课见！</p>`,100)]))}const u=s(e,[["render",o]]),i=JSON.parse('{"path":"/3.tech/83.PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/09_%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%AF%87-%E5%8D%B7%E7%A7%AF%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E7%94%A8%E5%8D%B7%E7%A7%AF%E4%B8%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%BC%80%E5%A4%A9%E7%9C%BC.html","title":"模型训练篇-卷积（上）：如何用卷积为计算机开天眼","lang":"zh-cn","frontmatter":{},"headers":[{"level":2,"title":"卷积","slug":"卷积","link":"#卷积","children":[{"level":3,"title":"最简单的情况","slug":"最简单的情况","link":"#最简单的情况","children":[]},{"level":3,"title":"标准的卷积","slug":"标准的卷积","link":"#标准的卷积","children":[]},{"level":3,"title":"Padding","slug":"padding","link":"#padding","children":[]}]},{"level":2,"title":"PyTorch 中的卷积","slug":"pytorch-中的卷积","link":"#pytorch-中的卷积","children":[{"level":3,"title":"验证 same 方式","slug":"验证-same-方式","link":"#验证-same-方式","children":[]}]},{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[]},{"level":2,"title":"每课一练","slug":"每课一练","link":"#每课一练","children":[]}],"git":{"updatedTime":1746672966000,"contributors":[{"name":"guoxin-qiu","username":"guoxin-qiu","email":"guoxin.qiu@outlook.com","commits":2,"url":"https://github.com/guoxin-qiu"}],"changelog":[{"hash":"873191059aa4709eddd6184a409223b5054edb2a","time":1746672966000,"email":"guoxin.qiu@outlook.com","author":"guoxin-qiu","message":"update: pytorch fixed"},{"hash":"b44b80ec6b8c2ebffa55c7b2b54259609c76baed","time":1745668690000,"email":"guoxin.qiu@outlook.com","author":"guoxin-qiu","message":"add pytorch course"}]},"filePathRelative":"3.tech/83.PyTorch深度学习实战/09_模型训练篇-卷积（上）：如何用卷积为计算机开天眼.md"}');export{u as comp,i as data};
