import{_ as a,c as t,a as n,o as i}from"./app-Dmwo-0Oh.js";const s={};function o(r,e){return i(),t("div",null,e[0]||(e[0]=[n('<h1 id="ai-云原生" tabindex="-1"><a class="header-anchor" href="#ai-云原生"><span>AI + 云原生</span></a></h1><h2 id="云原生-ai-套件" tabindex="-1"><a class="header-anchor" href="#云原生-ai-套件"><span>云原生 AI 套件</span></a></h2><p>云原生 AI 套件这个词源自于云计算行业，现在基本各家云公司都在做相关产品。云原生 AI 套件指的是在 Kubernetes 上定制化构建 AI 生产系统，底层封装对各类异构资源的统一管理，上层运行核心组件，实现资源运维管理，AI 任务调度和弹性伸缩，数据访问加速，工作流编排，可观测等等能力。</p><p>用白话来说，就是玩转 AI 的基础有两个，<strong>一是 GPU</strong> <strong>算力，二是复杂的环境搭建</strong>。由于 GPU 卡价格昂贵，资源稀缺，所以不论是企业还是个人，在 GPU 资源的管理和调度上，都要尽量做到极致，以达到降本增效的目的。第二是复杂的环境搭建，一套机器学习环境从 PyTorch、TensorFlow 等框架到 Pipeline 等工具的部署，非常繁琐。因此用 Kubernetes 来解决这两个痛点，是再适合不过了。Kubernetes 上有着 GPU-Operator 等等优秀的算力调度工具，而容器编排能力对于解决复杂环境部署也是小菜一碟。</p><p>在开源社区，有着一款被称为机器学习的“瑞士军刀”的产品，叫做 Kubeflow。Kubeflow 是由 Google 发起的开源 AI 开发平台，构建在 Kubernetes 之上，专门用来简化和自动化机器学习模型的开发、训练、部署和管理。如下图所示，Kubeflow 向下可以部署在任意 Kubernetes，其包含了 Kubeflow Notebooks 等多款组件，向上提供了 PyTorch 等训练框架以及 Hugging Face 等模型仓库。</p><p><img src="https://static001.geekbang.org/resource/image/99/a2/993419b132878355d3yycb0a06f7dba2.jpg?wh=1169x1115" alt="图片"></p><p>总的来说，Kubeflow 就像一个由各种技术栈和组件拼装成的“乐高”一样，开发中可以按需部署相应组件。</p><p>因此这种方式的 AI + 云原生，主要是通过发挥云原生的优势，优化 AI 资源调用，为 AI 训练提供可靠平台，提升 AI 训练效率。</p><h2 id="用自然语言操控运维-k8s" tabindex="-1"><a class="header-anchor" href="#用自然语言操控运维-k8s"><span>用自然语言操控运维 K8s</span></a></h2><p>我们先来回顾一下，人类与软件交互的发展。</p><p>执行器发展的初期是 CLI（命令行界面，Command Line Interface），用户需要在黑终端键入各种命令，来与软件交互，例如 K8s 的 kubectl ，是运维同学每天的必用工具。</p><p>后来随着图形化界面的发展，交互体系变成了 GUI（图形用户界面，Graphical User Interface），例如 K8s 的 Dashboard，操作变得更直观、更友好，无需记忆命令了。</p><p>在 AI 时代，开始出现了 LUI（语言用户界面，Language User Interface）的概念，即用户可以通过自然语言与软件交互，无需在繁琐的 UI 中查找某个功能的按钮藏在哪了。自然语言交互除了文字方式以外，还包括声音等方式，未来，运维全靠“喊”的年代或许不会久远。</p><p>那么，要实现用自然语言操控和运维 K8s，需要用到什么技术呢？第一是大模型需要具备足够的思考和推理能力，也就是传说中的 Agent，第二是需要 API 调用能力。这在我们后面的课程中，都会详细讲解。</p><p>所以总体来说，这种方式的 AI + 云原生，是一种“智赖孔明”的方式，AI 帮助我们在操控和运维 K8s 集群上节省了人力。</p><h2 id="ai-微服务———云原生-ai-网关" tabindex="-1"><a class="header-anchor" href="#ai-微服务———云原生-ai-网关"><span>AI 微服务———云原生 AI 网关</span></a></h2><p>做云原生特别是微服务的同学，一定绕不开的一个组件就是网关。举一个不完全恰当的例子，网关就像是银行门口的保安大爷，具备三大基础能力：</p><ol><li><p>保护：能保护银行办公人员的安全。</p></li><li><p>路由控制：为顾客提供路由服务，告诉你办什么业务要取什么号，最终路由到具体的窗口服务人员。</p></li><li><p>流量控制：会根据银行内部业务处理的实际情况，决定是否把卷帘门拉下来，来控制人流量。</p></li></ol><p>在这个场景中，每一个银行窗口的服务人员，就是微服务架构中的一个服务，取的号码便是 API ，我们通过 API 可以找到服务人员。而网关则在最开始对 API 做了管控。因此在微服务架构中，网关是一个 API 网关，可以将客户端接口与后端实现分离。在云原生时代，Kubernetes 是基础设施，服务全都部署在 Kubernetes 之上，因此 API 网关 作为 Kubenetes 上各服务的入口代理，变成了云原生 API 网关。</p><p>进入 AI 时代，随着 Agent 等技术的快速落地，网关也需要与时俱进，其不仅承担传统网关的功能，更是一个具备智能调度、自动化管理和自然语言交互能力的核心组件。它的引入，使得前端与后端的沟通不再局限于固定的 API 调用，而是通过自然语言与 AI Agent 进行互动，实现了人机对话的高度流畅和智能化。</p><p>AI 网关的核心优势在于其智能化的 API 管理能力。在传统的微服务架构中，API 网关的作用多是请求的转发与路由，而在 AI 微服务架构下，AI 网关的功能得以扩展，开始承担起根据自然语言指令智能调度后端 AI 服务的责任。这意味着，开发者、运维人员甚至非技术人员都可以通过简洁的语言与系统进行交互，从而减少了技术壁垒，提高了效率。</p><p>总的来说，AI 网关的引入，标志着云原生架构在 AI 微服务时代的全面升级，它通过自然语言接口、智能调度、动态优化等技术，简化了复杂系统的管理与调度过程，同时也为 AI 微服务的高效协同提供了全新的解决方案。随着智能化程度的不断提高，AI 网关必将成为未来 AI 应用架构的关键组成部分，推动着人工智能与云原生技术的深度融合，开辟出全新的技术发展路径。</p>',22)]))}const l=a(s,[["render",o]]),I=JSON.parse('{"path":"/3.tech/84.AIAgent/00.%20AI_%E4%BA%91%E5%8E%9F%E7%94%9F.html","title":"AI + 云原生","lang":"zh-cn","frontmatter":{},"headers":[{"level":2,"title":"云原生 AI 套件","slug":"云原生-ai-套件","link":"#云原生-ai-套件","children":[]},{"level":2,"title":"用自然语言操控运维 K8s","slug":"用自然语言操控运维-k8s","link":"#用自然语言操控运维-k8s","children":[]},{"level":2,"title":"AI 微服务———云原生 AI 网关","slug":"ai-微服务———云原生-ai-网关","link":"#ai-微服务———云原生-ai-网关","children":[]}],"git":{"updatedTime":1749262836000,"contributors":[{"name":"guoxin-qiu","username":"guoxin-qiu","email":"guoxin.qiu@outlook.com","commits":1,"url":"https://github.com/guoxin-qiu"}],"changelog":[{"hash":"0e82c49946907ddefcb6ccb279dc6debbb8ca726","time":1749262836000,"email":"guoxin.qiu@outlook.com","author":"guoxin-qiu","message":"add 20250607"}]},"filePathRelative":"3.tech/84.AIAgent/00. AI+云原生.md"}');export{l as comp,I as data};
