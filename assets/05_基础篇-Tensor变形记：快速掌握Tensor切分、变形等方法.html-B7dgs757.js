import{_ as s,c as a,b as p,o as t}from"./app-C01vnHKY.js";const e={};function o(c,n){return t(),a("div",null,n[0]||(n[0]=[p(`<h1 id="基础篇-tensor-变形记-快速掌握-tensor-切分、变形等方法" tabindex="-1"><a class="header-anchor" href="#基础篇-tensor-变形记-快速掌握-tensor-切分、变形等方法"><span>基础篇 Tensor 变形记：快速掌握 Tensor 切分、变形等方法</span></a></h1><p>上节课我们一起学习了 Tensor 的基础概念，也熟悉了创建、转换、维度变换等操作，掌握了这些基础知识，你就可以做一些简单的 Tensor 相关的操作了。</p><p>不过，要想在实际的应用中更灵活地用好 Tensor，Tensor 的连接、切分等操作也是必不可少的。今天这节课，咱们就通过一些例子和图片来一块学习下。虽然这几个操作比较有难度，但只要你耐心听我讲解，然后上手练习，还是可以拿下的。</p><h2 id="tensor-的连接操作" tabindex="-1"><a class="header-anchor" href="#tensor-的连接操作"><span>Tensor 的连接操作</span></a></h2><p>在项目开发中，深度学习某一层神经元的数据可能有多个不同的来源，那么就需要将数据进行组合，这个组合的操作，我们称之为<strong>连接</strong>。</p><h3 id="cat" tabindex="-1"><a class="header-anchor" href="#cat"><span>cat</span></a></h3><p>连接的操作函数如下。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>tensors<span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> out <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>cat 是 concatnate 的意思，也就是拼接、联系的意思。该函数有两个重要的参数需要你掌握。</p><p>第一个参数是 tensors，它很好理解，就是若干个我们准备进行拼接的 Tensor。</p><p>第二个参数是 dim，我们回忆一下 Tensor 的定义，Tensor 的维度（秩）是有多种情况的。比如有两个 3 维的 Tensor，可以有几种不同的拼接方式（如下图），dim 参数就可以对此作出约定。</p><p><img src="https://static001.geekbang.org/resource/image/61/3c/61bd88f3yy8d0ca07799f36540d3473c.jpg?wh=1285x862" alt="图片"></p><p>看到这里，你可能觉得上面画的图是三维的，看起来比较晦涩，所以咱们先从简单的二维的情况说起，我们先声明两个 3x3 的矩阵，代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B<span class="token operator">=</span><span class="token number">2</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们先看看 dim=0 的情况，拼接的结果是怎样的：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>你会发现，两个矩阵是按照“行”的方向拼接的。</p><p>我们接下来再看看，dim=1 的情况是怎样的：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> D<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> D</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>显然，两个矩阵，是按照“列”的方向拼接的。那如果 Tensor 是三维甚至更高维度的呢？其实道理也是一样的，dim 的数值是多少，两个矩阵就会按照相应维度的方向链接两个 Tensor。</p><p>看到这里你可能会问了，cat 实际上是将多个 Tensor 在已有的维度上进行连接，那如果想增加新的维度进行连接，又该怎么做呢？这时候就需要 stack 函数登场了。</p><h3 id="stack" tabindex="-1"><a class="header-anchor" href="#stack"><span>stack</span></a></h3><p>为了让你加深理解，我们还是结合具体例子来看看。假设我们有两个二维矩阵 Tensor，把它们“堆叠”放在一起，构成一个三维的 Tensor，如下图：</p><p><img src="https://static001.geekbang.org/resource/image/9d/66/9d991a0d571e2733ba15d67566f65166.jpg?wh=1160x770" alt="图片"></p><p>这相当于原来的维度（秩）是 2，现在变成了 3，变成了一个立体的结构，增加了一个维度。你需要注意的是，这跟前面的 cat 不同，cat 中示意图的例子，原来就是 3 维的，cat 之后仍旧是 3 维的，而现在咱们是<strong>从 2 维变成了 3 维</strong>。</p><p>在实际图像算法开发中，咱们有时候需要将多个单通道 Tensor（2 维）合并，得到多通道的结果（3 维）。而实现这种增加维度拼接的方法，我们把它叫做 stack。</p><p>stack 函数的定义如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>其中，inputs 表示需要拼接的 Tensor，dim 表示新建立维度的方向。</p><p>那 stack 如何使用呢？我们一块来看一个例子：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B<span class="token operator">=</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C<span class="token operator">=</span>torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> D<span class="token operator">=</span>torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> D</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>结合代码，我们可以看到，首先我们构建了两个 4 元素向量 A 和 B，它们的维度是 1。然后，我们在 dim=0，也就是“行”的方向上新建一个维度，这样维度就成了 2，也就得到了 C。而对于 D，我们则是在 dim=1，也就是“列”的方向上新建维度。</p><h2 id="tensor-的切分操作" tabindex="-1"><a class="header-anchor" href="#tensor-的切分操作"><span>Tensor 的切分操作</span></a></h2><p>学完了连接操作之后，我们再来看看连接的逆操作：<strong>切分</strong>。</p><p>切分就是连接的逆过程，有了刚才的经验，你很容易就会想到，切分的操作也应该有很多种，比如切片、切块等。没错，切分的操作主要分为三种类型：chunk、split、unbind。</p><p>乍一看有不少，其实是因为它们各有特点，适用于不同的使用情景，让我们一起看一下。</p><h3 id="chunk" tabindex="-1"><a class="header-anchor" href="#chunk"><span>chunk</span></a></h3><p>chunk 的作用就是将 Tensor 按照声明的 dim，进行尽可能平均的划分。</p><p>比如说，我们有一个 32channel 的特征，需要将其按照 channel 均匀分成 4 组，每组 8 个 channel，这个切分就可以通过 chunk 函数来实现。具体函数如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> chunks<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>我们挨个来看看函数中涉及到的三个参数：</p><p>首先是 input，它表示要做 chunk 操作的 Tensor。</p><p>接着，我们看下 chunks，它代表将要被划分的块的数量，而不是每组的数量。请注意，<strong>chunks 必须是整型</strong>。</p><p>最后是 dim，想想这个参数是什么意思呢？对，就是按照哪个维度来进行 chunk。</p><p>还是跟之前一样，我们通过几个代码例子直观感受一下。我们从一个简单的一维向量开始：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B <span class="token operator">=</span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>A<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这里我们通过 chunk 函数，将原来 10 位长度的 Tensor A，切分成了两个一样 5 位长度的向量。（注意，B 是两个切分结果组成的 tuple）。</p><p>那如果 chunk 参数不能够整除的话，结果会是怎样的呢？我们接着往下看：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B <span class="token operator">=</span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>A<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们发现，10 位长度的 Tensor A，切分成了三个向量，长度分别是 4，4，2 位。这是怎么分的呢，不应该是 3，3，4 这样更为平均的方式么？</p><p>想要解决问题，就得找到规律。让我们再来看一个更大一点的例子，将 A 改为 17 位长度。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B <span class="token operator">=</span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>A<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>17 位长度的 Tensor A，切分成了四个分别为 5，5，5，2 位长度的向量。这时候你就会发现，其实在计算每个结果元素个数的时候，chunk 函数是先做除法，然后再向上取整得到每组的数量。</p><p>比如上面这个例子，17/4=4.25，向上取整就是 5，那就先逐个生成若干个长度为 5 的向量，最后不够的就放在一块，作为最后一个向量（长度 2）。</p><p>那如果 chunk 参数大于 Tensor 可以切分的长度，又要怎么办呢？我们实际操作一下，代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B <span class="token operator">=</span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>A<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>显然，被切分的 Tensor 只能分成若干个长度为 1 的向量。</p><p>由此可以推论出二维的情况，我们再举一个例子， 看看二维矩阵 Tensor 的情况 ：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B <span class="token operator">=</span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>A<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>还是跟前面的 cat 一样，这里的 dim 参数，表示的是第 dim 维度方向上进行切分。</p><p>刚才介绍的 chunk 函数，是按照“切分成确定的份数”来进行切分的，那如果想按照“每份按照确定的大小”来进行切分，该怎样做呢？PyTorch 也提供了相应的方法，叫做 split。</p><h3 id="split" tabindex="-1"><a class="header-anchor" href="#split"><span>split</span></a></h3><p>split 的函数定义如下，跟前面一样，我们还是分别看看这里涉及的参数。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> split_size_or_sections<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>首先是 tensor，也就是待切分的 Tensor。</p><p>然后是 split_size_or_sections 这个参数。当它为整数时，表示将 tensor 按照每块大小为这个整数的数值来切割；当这个参数为列表时，则表示将此 tensor 切成和列表中元素一样大小的块。</p><p>最后同样是 dim，它定义了要按哪个维度切分。</p><p>同样的，我们举几个例子来看一下 split 的具体操作。首先是 split_size_or_sections 是整数的情况。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6418</span><span class="token punctuation">,</span> <span class="token number">0.4171</span><span class="token punctuation">,</span> <span class="token number">0.7372</span><span class="token punctuation">,</span> <span class="token number">0.0733</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.0935</span><span class="token punctuation">,</span> <span class="token number">0.2372</span><span class="token punctuation">,</span> <span class="token number">0.6912</span><span class="token punctuation">,</span> <span class="token number">0.8677</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.5263</span><span class="token punctuation">,</span> <span class="token number">0.4145</span><span class="token punctuation">,</span> <span class="token number">0.9292</span><span class="token punctuation">,</span> <span class="token number">0.5671</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.2284</span><span class="token punctuation">,</span> <span class="token number">0.6938</span><span class="token punctuation">,</span> <span class="token number">0.0956</span><span class="token punctuation">,</span> <span class="token number">0.3823</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B<span class="token operator">=</span>torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>A<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6418</span><span class="token punctuation">,</span> <span class="token number">0.4171</span><span class="token punctuation">,</span> <span class="token number">0.7372</span><span class="token punctuation">,</span> <span class="token number">0.0733</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.0935</span><span class="token punctuation">,</span> <span class="token number">0.2372</span><span class="token punctuation">,</span> <span class="token number">0.6912</span><span class="token punctuation">,</span> <span class="token number">0.8677</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5263</span><span class="token punctuation">,</span> <span class="token number">0.4145</span><span class="token punctuation">,</span> <span class="token number">0.9292</span><span class="token punctuation">,</span> <span class="token number">0.5671</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.2284</span><span class="token punctuation">,</span> <span class="token number">0.6938</span><span class="token punctuation">,</span> <span class="token number">0.0956</span><span class="token punctuation">,</span> <span class="token number">0.3823</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在这个例子里，我们看到，原来 4x4 大小的 Tensor A，沿着第 0 维度，也就是沿“行”的方向，按照每组 2“行”的大小进行切分，得到了两个 2x4 大小的 Tensor。</p><p>那么问题来了，如果 split_size_or_sections 不能整除对应方向的大小的话，会有怎样的结果呢？我们将代码稍作修改就好了：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C<span class="token operator">=</span>torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>A<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6418</span><span class="token punctuation">,</span> <span class="token number">0.4171</span><span class="token punctuation">,</span> <span class="token number">0.7372</span><span class="token punctuation">,</span> <span class="token number">0.0733</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.0935</span><span class="token punctuation">,</span> <span class="token number">0.2372</span><span class="token punctuation">,</span> <span class="token number">0.6912</span><span class="token punctuation">,</span> <span class="token number">0.8677</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.5263</span><span class="token punctuation">,</span> <span class="token number">0.4145</span><span class="token punctuation">,</span> <span class="token number">0.9292</span><span class="token punctuation">,</span> <span class="token number">0.5671</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.2284</span><span class="token punctuation">,</span> <span class="token number">0.6938</span><span class="token punctuation">,</span> <span class="token number">0.0956</span><span class="token punctuation">,</span> <span class="token number">0.3823</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>根据刚才的代码我们就能发现，原来，PyTorch 会尽可能凑够每一个结果，使得其对应 dim 的数据大小等于 split_size_or_sections。如果最后剩下的不够，那就把剩下的内容放到一块，作为最后一个结果。</p><p>接下来，我们再看一下 split_size_or_sections 是列表时的情况。刚才提到了，当 split_size_or_sections 为列表的时候，表示将此 tensor 切成和列表中元素大小一样的大小的块，我们来看一段对应的代码：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1005</span><span class="token punctuation">,</span> <span class="token number">0.9666</span><span class="token punctuation">,</span> <span class="token number">0.5322</span><span class="token punctuation">,</span> <span class="token number">0.6775</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.4990</span><span class="token punctuation">,</span> <span class="token number">0.8725</span><span class="token punctuation">,</span> <span class="token number">0.5627</span><span class="token punctuation">,</span> <span class="token number">0.8360</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.3427</span><span class="token punctuation">,</span> <span class="token number">0.9351</span><span class="token punctuation">,</span> <span class="token number">0.7291</span><span class="token punctuation">,</span> <span class="token number">0.7306</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.7939</span><span class="token punctuation">,</span> <span class="token number">0.3007</span><span class="token punctuation">,</span> <span class="token number">0.7258</span><span class="token punctuation">,</span> <span class="token number">0.9482</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.7249</span><span class="token punctuation">,</span> <span class="token number">0.7534</span><span class="token punctuation">,</span> <span class="token number">0.0027</span><span class="token punctuation">,</span> <span class="token number">0.7793</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B<span class="token operator">=</span>torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>A<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1005</span><span class="token punctuation">,</span> <span class="token number">0.9666</span><span class="token punctuation">,</span> <span class="token number">0.5322</span><span class="token punctuation">,</span> <span class="token number">0.6775</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.4990</span><span class="token punctuation">,</span> <span class="token number">0.8725</span><span class="token punctuation">,</span> <span class="token number">0.5627</span><span class="token punctuation">,</span> <span class="token number">0.8360</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.3427</span><span class="token punctuation">,</span> <span class="token number">0.9351</span><span class="token punctuation">,</span> <span class="token number">0.7291</span><span class="token punctuation">,</span> <span class="token number">0.7306</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.7939</span><span class="token punctuation">,</span> <span class="token number">0.3007</span><span class="token punctuation">,</span> <span class="token number">0.7258</span><span class="token punctuation">,</span> <span class="token number">0.9482</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">0.7249</span><span class="token punctuation">,</span> <span class="token number">0.7534</span><span class="token punctuation">,</span> <span class="token number">0.0027</span><span class="token punctuation">,</span> <span class="token number">0.7793</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这部分代码怎么解释呢？其实也很好理解，就是将 Tensor A，沿着第 0 维进行切分，每一个结果对应维度上的尺寸或者说大小，分别是 2（行），3（行）。</p><h3 id="unbind" tabindex="-1"><a class="header-anchor" href="#unbind"><span>unbind</span></a></h3><p>通过学习前面的几个函数，咱们知道了怎么按固定大小做切分，或者按照索引 index 来进行选择。现在我们想象一个应用场景，如果我们现在有一个 3 channel 图像的 Tensor，想要逐个获取每个 channel 的数据，该怎么做呢？</p><p>假如用 chunk 的话，我们需要将 chunks 设为 3；如果用 split 的话，需要将 split_size_or_sections 设为 1。</p><p>虽然它们都可以实现相同的目的，但是如果 channel 数量很大，逐个去取也比较折腾。这时候，就需要用到另一个函数：unbind，它的函数定义如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>其中，input 表示待处理的 Tensor，dim 还是跟前面的函数一样，表示切片的方向。</p><p>我们结合例子来理解：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b<span class="token operator">=</span>torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span>A<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在这个例子中，我们首先创建了一个 4x4 的二维矩阵 Tensor，随后我们从第 0 维，也就是“行”的方向进行切分 ，因为矩阵有 4 行，所以就会得到 4 个结果。</p><p>接下来，我们看一下：如果从第 1 维，也就是“列”的方向进行切分，会是怎样的结果呢：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b<span class="token operator">=</span>torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span>A<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b</span>
<span class="line"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>不难发现，这里是按照“列”的方向进行拆解的。所以，<strong>unbind 是一种降维切分的方式</strong>，相当于删除一个维度之后的结果。</p><h2 id="tensor-的索引操作" tabindex="-1"><a class="header-anchor" href="#tensor-的索引操作"><span>Tensor 的索引操作</span></a></h2><p>你有没有发现，刚才我们讲的 chunk 和 split 操作，我们都是将数据整体进行切分，并获得全部结果。但有的时候，我们只需要其中的一部分，这要怎么做呢？一个很自然的想法就是，直接告诉 Tensor 我想要哪些部分，这种方法我们称为索引操作。</p><p>索引操作有很多方式，有提供好现成 API 的，也有用户自行定制的操作，其中最常用的两个操作就是 index_select 和 masked_select，我们分别去看看用法。</p><h3 id="index-select" tabindex="-1"><a class="header-anchor" href="#index-select"><span>index_select</span></a></h3><p>这里就需要 index_select 这个函数了，其定义如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> index<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这里的 tensor、dim 跟前面函数里的一样，不再赘述。我们重点看一看 index，它表示从 dim 维度中的哪些位置选择数据，这里需要注意，index<strong>是 torch.Tensor 类型</strong>。</p><p>还是跟之前一样，我们来看几个示例代码：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B<span class="token operator">=</span>torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>A<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> B</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C<span class="token operator">=</span>torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>A<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在这个例子中，我们先创建了一个 4x4 大小的矩阵 Tensor A。然后，我们从第 0 维选择第 1（行）和 3（行）的数据，并得到了最终的 Tensor B，其大小为 2x4。随后我们从 Tensor A 中选择第 0（列）和 3（列）的数据，得到了最终的 Tensor C，其大小为 4x2。</p><p>怎么样，是不是非常简单？</p><h3 id="masked-select" tabindex="-1"><a class="header-anchor" href="#masked-select"><span>masked_select</span></a></h3><p>刚才介绍的 indexed_select，它是基于给定的索引来进行数据提取的。但有的时候，我们还想通过一些判断条件来进行选择，比如提取深度学习网络中某一层中数值大于 0 的参数。</p><p>这时候，就需要用到 PyTorch 提供的 masked_select 函数了，我们先来看它的定义：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line">torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> mask<span class="token punctuation">,</span> out<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> </span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这里我们只需要关心前两个参数，input 和 mask。</p><p>input 表示待处理的 Tensor。mask 代表掩码张量，也就是满足条件的特征掩码。这里你需要注意的是，mask 须跟 input 张量有相同数量的元素数目，但形状或维度不需要相同。</p><p>你是不是还感觉有些云里雾里？让我来举一个例子，你看了之后，一下子就能明白。</p><p>你在平时的练习中有没有想过，如果我们让 Tensor 和数字做比较，会有什么样的结果？比如后面这段代码，我们随机生成一个 5 位长度的 Tensor A：</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code><span class="line">&gt;&gt;&gt; A=torch.rand(5)</span>
<span class="line">&gt;&gt;&gt; A</span>
<span class="line">tensor([0.3731, 0.4826, 0.3579, 0.4215, 0.2285])</span>
<span class="line">&gt;&gt;&gt; B=A&gt;0.3</span>
<span class="line">&gt;&gt;&gt; B</span>
<span class="line">tensor([ True,  True,  True,  True, False])</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在这段代码里，我们让 A 跟 0.3 做比较，得到了一个新的 Tensor，内部每一个数值表示的是 A 中对应数值是否大于 0.3。</p><p>比如第一个数值原来是 0.3731，大于 0.3，所以是 True；最后一个数值 0.2285 小于 0.3，所以是 False。</p><p>这个新的 Tensor 其实就是一个掩码张量，它的每一位表示了一个判断条件是否成立的结果。</p><p>然后，我们继续写一段代码，看看基于掩码 B 的选择是怎样的结果 ：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C<span class="token operator">=</span>torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.3731</span><span class="token punctuation">,</span> <span class="token number">0.4826</span><span class="token punctuation">,</span> <span class="token number">0.3579</span><span class="token punctuation">,</span> <span class="token number">0.4215</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>你会发现，C 实际上得到的就是：A 中“**满足 B 里面元素值为 True 的”**对应位置的数据。</p><p>好了，这下你应该知道了 masked_select 的作用了吧？其实就是我们根据要筛选的条件，得到一个掩码张量，然后用这个张量去提取 Tensor 中的数据。</p><p>根据这个思路，上面的例子就可以简化为：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.3731</span><span class="token punctuation">,</span> <span class="token number">0.4826</span><span class="token punctuation">,</span> <span class="token number">0.3579</span><span class="token punctuation">,</span> <span class="token number">0.4215</span><span class="token punctuation">,</span> <span class="token number">0.2285</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C<span class="token operator">=</span>torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>A<span class="token punctuation">,</span> A<span class="token operator">&gt;</span><span class="token number">0.3</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> C</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.3731</span><span class="token punctuation">,</span> <span class="token number">0.4826</span><span class="token punctuation">,</span> <span class="token number">0.3579</span><span class="token punctuation">,</span> <span class="token number">0.4215</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>是不是非常简单呢？</p><h2 id="小结" tabindex="-1"><a class="header-anchor" href="#小结"><span>小结</span></a></h2><p>恭喜你完成了这节课的学习。这节课，我们一同学习了 Tensor 里更加高级的操作，包括 Tensor 之间的连接操作，Tensor 内部的切分操作，以及基于索引或者筛选条件的数据选择操作。</p><p>当然了，在使用这些函数的时候，你最需要关注的就是边界的数值大小，具体来说就是维度和大小相关的参数，一定要提前仔细计算好，要不然就会产生错误的结果。</p><p>结合众多的例子，我相信你一定可以拿下这些操作。</p><p>这里我特意给你梳理了一张表格，总结归纳了 Tensor 中的主要函数跟用法。不过这些参数咱们也不用死记硬背，我们在使用的时候，根据需要灵活查询相关的参数列表即可。 <img src="https://static001.geekbang.org/resource/image/d1/ba/d195706087f784c8e1e1c7c7b25a22ba.jpg?wh=3020x2455" alt=""> 通过这两节课，我们搞懂了 Tensor 的一系列操作，在以后的项目中，你就可以游刃有余地对 Tensor 进行各种花式操作了，加油!</p><h2 id="每课一练" tabindex="-1"><a class="header-anchor" href="#每课一练"><span>每课一练</span></a></h2><p>现在有个 Tensor，如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> A</span>
<span class="line">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们想提取出其中第一行的第一个，第二行的第一、第二个，第三行的最后一个，该怎么做呢？</p><p>欢迎你在留言区跟我交流互动，也推荐你把这节课分享给更多同事、朋友！</p>`,128)]))}const l=s(e,[["render",o]]),i=JSON.parse('{"path":"/3.tech/83.PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/05_%E5%9F%BA%E7%A1%80%E7%AF%87-Tensor%E5%8F%98%E5%BD%A2%E8%AE%B0%EF%BC%9A%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1Tensor%E5%88%87%E5%88%86%E3%80%81%E5%8F%98%E5%BD%A2%E7%AD%89%E6%96%B9%E6%B3%95.html","title":"基础篇 Tensor 变形记：快速掌握 Tensor 切分、变形等方法","lang":"zh-cn","frontmatter":{},"headers":[{"level":2,"title":"Tensor 的连接操作","slug":"tensor-的连接操作","link":"#tensor-的连接操作","children":[{"level":3,"title":"cat","slug":"cat","link":"#cat","children":[]},{"level":3,"title":"stack","slug":"stack","link":"#stack","children":[]}]},{"level":2,"title":"Tensor 的切分操作","slug":"tensor-的切分操作","link":"#tensor-的切分操作","children":[{"level":3,"title":"chunk","slug":"chunk","link":"#chunk","children":[]},{"level":3,"title":"split","slug":"split","link":"#split","children":[]},{"level":3,"title":"unbind","slug":"unbind","link":"#unbind","children":[]}]},{"level":2,"title":"Tensor 的索引操作","slug":"tensor-的索引操作","link":"#tensor-的索引操作","children":[{"level":3,"title":"index_select","slug":"index-select","link":"#index-select","children":[]},{"level":3,"title":"masked_select","slug":"masked-select","link":"#masked-select","children":[]}]},{"level":2,"title":"小结","slug":"小结","link":"#小结","children":[]},{"level":2,"title":"每课一练","slug":"每课一练","link":"#每课一练","children":[]}],"git":{"updatedTime":1746672966000,"contributors":[{"name":"guoxin-qiu","username":"guoxin-qiu","email":"guoxin.qiu@outlook.com","commits":2,"url":"https://github.com/guoxin-qiu"}],"changelog":[{"hash":"873191059aa4709eddd6184a409223b5054edb2a","time":1746672966000,"email":"guoxin.qiu@outlook.com","author":"guoxin-qiu","message":"update: pytorch fixed"},{"hash":"b44b80ec6b8c2ebffa55c7b2b54259609c76baed","time":1745668690000,"email":"guoxin.qiu@outlook.com","author":"guoxin-qiu","message":"add pytorch course"}]},"filePathRelative":"3.tech/83.PyTorch深度学习实战/05_基础篇-Tensor变形记：快速掌握Tensor切分、变形等方法.md"}');export{l as comp,i as data};
